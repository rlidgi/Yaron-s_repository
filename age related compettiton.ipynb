{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-15T06:15:48.275167Z",
     "iopub.status.busy": "2023-06-15T06:15:48.274633Z",
     "iopub.status.idle": "2023-06-15T06:16:35.409242Z",
     "shell.execute_reply": "2023-06-15T06:16:35.407755Z",
     "shell.execute_reply.started": "2023-06-15T06:15:48.275126Z"
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1679013193478,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "jVl_7DfKQj4R",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log_loss, make_scorer\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[0;32m     13\u001b[0m optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mset_verbosity(optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mWARNING)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "#!pip install optuna\n",
    "#!pip install xgboost\n",
    "#!pip install lightgbm\n",
    "#!pip install imblearn\n",
    "\n",
    "#!pip install tensorflow\n",
    "\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import log_loss, make_scorer\n",
    "import os\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import log_loss\n",
    "import math\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import validation_curve\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "#from verstack import FeatureSelector\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import tree\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import *\n",
    "\n",
    "import statsmodels.tools.tools\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # y_true: correct labels 0, 1\n",
    "    # y_pred: predicted probabilities of class=1\n",
    "    # Implements the Evaluation equation with w_0 = w_1 = 1.\n",
    "    # Calculate the number of observations for each class\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    # Calculate the predicted probabilities for each class\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    # Calculate the average log loss for each class\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0)) / N_0\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1)) / N_1\n",
    "    # return the (not further weighted) average of the averages\n",
    "    return (log_loss_0 + log_loss_1)/2\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-08-18T15:33:25.498671Z",
     "iopub.status.idle": "2022-08-18T15:33:25.499323Z",
     "shell.execute_reply": "2022-08-18T15:33:25.499128Z",
     "shell.execute_reply.started": "2022-08-18T15:33:25.499106Z"
    },
    "id": "UDT84nOzQj4U"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T06:30:04.612755Z",
     "iopub.status.busy": "2023-06-15T06:30:04.612384Z",
     "iopub.status.idle": "2023-06-15T06:30:04.681938Z",
     "shell.execute_reply": "2023-06-15T06:30:04.681066Z",
     "shell.execute_reply.started": "2023-06-15T06:30:04.612713Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#train= pd.read_csv(\"C:/Users/rliog/Downloads/train_rev2.csv\")\n",
    "train= pd.read_csv(\"C:/Users/rliog/Downloads/train_rev.csv\")\n",
    "train.columns=train.columns.str.strip()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.get_dummies(train, columns=['Beta_pred','Delta_pred','Gamma_pred'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only Delta good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Alpha','Beta','Delta','Gamma'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['EL'].fillna(train['EL'].mean(),inplace=True)\n",
    "train['BQ'].fillna(train['BQ'].mean(),inplace=True)\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=train.drop(['Class'],axis=1)\n",
    "target=train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    \n",
    "    positive_count_train =target.value_counts()[1]\n",
    "    sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, 1: positive_count_train},random_state=i, replacement=True)\n",
    "    predictors, target = sampler.fit_resample(predictors, target)\n",
    "    lgb_train = lgbm.Dataset(predictors, target,free_raw_data=False)\n",
    "    \n",
    "    \n",
    "    model = lgbm.train(params, lgb_train, \n",
    "                      \n",
    "                      num_boost_round=500,\n",
    "                      verbose_eval=200)\n",
    "    \n",
    "    pred = model.predict(predictors_test,num_iteration=model.best_iteration)\n",
    "\n",
    "    if i == 0:\n",
    "        output2 = pd.DataFrame(pred, columns=['pred' + str(i + 1)])\n",
    "    else:\n",
    "        output = pd.DataFrame(pred, columns=['pred' + str(i + 1)])\n",
    "        output2 = pd.concat([output2, output], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = output2.mean(axis='columns')\n",
    "#submit=pd.DataFrame(dfTs[\"Id\"], columns=[\"Id\"])\n",
    "np.array(pred)>.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(target_test)==(np.array(pred)>.5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_test=pd.DataFrame(predictors_test.copy())\n",
    "df_test['probabilities']=pred\n",
    "\n",
    "df_test['actual']=np.where(target_test=='A',0,1)\n",
    "RMSE = log_loss(target_test, pred)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_count_train = target.value_counts()[1]\n",
    "sampler = RandomUnderSampler(sampling_strategy={0: positive_count_train, 1: positive_count_train},random_state=10, replacement=True)\n",
    "predictors, target = sampler.fit_resample(predictors, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1= pd.read_csv(\"C:/Users/rliog/Downloads/train_rev.csv\")\n",
    "target=train1['Alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into predictors and target variables\n",
    "target = train['Class']\n",
    "\n",
    "predictors=train.drop(['Class','Alpha','Gamma','Beta','Delta'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test sets\n",
    "\n",
    "#predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2)\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2,random_state=190)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into predictors and target variables\n",
    "target = train['Class']\n",
    "predictors1 = train.drop(['Class','Alpha','Beta','Delta','Gamma'], axis=1)\n",
    "#predictors1 = train.drop(['Beta_pred','Delta_pred','Gamma_pred'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:45:48.068397Z",
     "iopub.status.busy": "2023-06-15T07:45:48.068031Z",
     "iopub.status.idle": "2023-06-15T07:45:48.110892Z",
     "shell.execute_reply": "2023-06-15T07:45:48.108436Z",
     "shell.execute_reply.started": "2023-06-15T07:45:48.068375Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train and test sets\n",
    "\n",
    "#predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2)\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors1, target, test_size=0.2,random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#predictors1 = pd.get_dummies(predictors1, columns=['Delta_pred'], drop_first=True)\n",
    "predictors1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:46:13.595333Z",
     "iopub.status.busy": "2023-06-15T07:46:13.594957Z",
     "iopub.status.idle": "2023-06-15T07:46:13.603601Z",
     "shell.execute_reply": "2023-06-15T07:46:13.602291Z",
     "shell.execute_reply.started": "2023-06-15T07:46:13.595303Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train and test sets\n",
    "\n",
    "#predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2)\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2,random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = pd.get_dummies(predictors, columns=['Delta'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test sets\n",
    "\n",
    "#predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2)\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2,random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#greeks=pd.read_csv(\"C:/Users/rliog/Downloads/greeks.csv\")\n",
    "train= pd.read_csv(\"C:/Users/rliog/Downloads/train (13).csv\")\n",
    "train.columns=train.columns.str.strip()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= pd.read_csv(\"C:/Users/rliog/Downloads/test (11).csv\")\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictors_train.info()\n",
    "train['EL'].fillna(train['EL'].mean(),inplace=True)\n",
    "train['BQ'].fillna(train['BQ'].mean(),inplace=True)\n",
    "\n",
    "#predictors.info()\n",
    "#predictors=predictors.dropna(inplace=True)\n",
    "train = pd.get_dummies(train, columns=['EJ'], drop_first=True)\n",
    "train = pd.get_dummies(train, columns=['Beta','Delta','Gamma'], drop_first=True)\n",
    "\n",
    "train=train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictors_test.info()\n",
    "test['EL'].fillna(test['EL'].mean(),inplace=True)\n",
    "test['BQ'].fillna(test['BQ'].mean(),inplace=True)\n",
    "\n",
    "#predictors.info()\n",
    "#predictors=predictors.dropna(inplace=True)\n",
    "test = pd.get_dummies(test, columns=['EJ'], drop_first=False)\n",
    "\n",
    "\n",
    "test=test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train.columns:\n",
    "    plt.hist(train[i],bins=40)\n",
    "    print(\"this is number\", i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revise training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Beta_pred']=model_GBC.predict(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Delta_pred']=model_GBC.predict(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Gamma_pred']=model_GBC.predict(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_rev.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find influential outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into predictors and target variables\n",
    "target = train['Class']\n",
    "predictors = train.drop(['Class','Alpha'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate and fit the visualizer\n",
    "visualizer = CooksDistance()\n",
    "visualizer.fit(predictors, target)\n",
    "visualizer.show()\n",
    "e=visualizer.distance_\n",
    "e\n",
    "np.argmax((np.array(e)))\n",
    "#e[0:40]\n",
    "#e[617]\n",
    "e.iloc[500:510]\n",
    "#greeks.drop(160,inplace=True)\n",
    "#train.drop(511,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "    'folder': ['SF_20141231','SF_20141231','SF_20141231','SF_20141231','SF_20141231','SF_20141231','SF_20141231'], \n",
    "        'fn': ['IF1501_20141231.csv','IF1502_20141231.csv','IF1503_20141231.csv','IF1506_20141231.csv','TF1503_20141231.csv','TF1506_20141231.csv','TF1509_20141231.csv'], \n",
    "        'volume': ['162.0000','4.0000','6.0000','7.0000','4.0000','0.0000','0.0000']}\n",
    "raw_data=pd.DataFrame(raw_data)\n",
    "#raw_data['volume'].argmax()\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "    'folder': ['SF_20141231','SF_20141231','SF_20141231','SF_20141231','SF_20141231','SF_20141231','SF_20141231'], \n",
    "        'fn': ['IF1501_20141231.csv','IF1502_20141231.csv','IF1503_20141231.csv','IF1506_20141231.csv','TF1503_20141231.csv','TF1506_20141231.csv','TF1509_20141231.csv'], \n",
    "        'volume': ['162.0000','4.0000','6.0000','7.0000','4.0000','0.0000','0.0000']}\n",
    "\n",
    "combine1 = pd.DataFrame(raw_data,index=[1428,1429,1430,1431,1432,1433,1434])\n",
    "combine1['volume'] = pd.to_numeric(combine1['volume'])\n",
    "combine1['volume'].idxmax(axis=0)\n",
    "combine1['volume'].argmax()\n",
    "combine1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target\n",
    "#predictors.drop(160,inplace=True)\n",
    "#predictors.loc[160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install yellowbrick\n",
    "from yellowbrick.regressor import CooksDistance\n",
    "\n",
    "\n",
    "# Instantiate and fit the visualizer\n",
    "visualizer = CooksDistance()\n",
    "visualizer.fit(predictors, target)\n",
    "visualizer.show()\n",
    "e=visualizer.distance_\n",
    "type(e)\n",
    "#index(e==52.692285317481065)\n",
    "#e.to_csv('ece.csv')\n",
    "#r=pd.DataFrame(e)\n",
    "#ee=np.array(r)\n",
    "#ee=ee.reshape((1,612))\n",
    "#eee=np.sort(ee)\n",
    "#eee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into predictors and target variables\n",
    "target = train['Class']\n",
    "predictors = train.drop(['Class','Alpha'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test sets\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:13.640330Z",
     "iopub.status.busy": "2023-03-23T22:55:13.639596Z",
     "iopub.status.idle": "2023-03-23T22:55:13.654567Z",
     "shell.execute_reply": "2023-03-23T22:55:13.653653Z",
     "shell.execute_reply.started": "2023-03-23T22:55:13.640286Z"
    },
    "executionInfo": {
     "elapsed": 150,
     "status": "ok",
     "timestamp": 1679000883135,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "A6z8p_DoQj4c",
    "outputId": "a86f2ab2-aa0a-4aab-89fc-7428976d241f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(predictors.shape[1]):\n",
    "    plt.scatter(np.log(predictors.iloc[:,i]), target)\n",
    "    print(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_lin=linear_model.Ridge(alpha=1.0)\n",
    "model_lin=linear_model.LinearRegression()\n",
    "\n",
    "model_lin.fit(predictors_train,target_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train=model_lin.predict(predictors_train)\n",
    "prediction_test=model_lin.predict(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train results\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE = log_loss(target_train, prediction_train)\n",
    "print(\"The score is %.6f\" % RMSE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test results\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE =  log_loss(target_test, prediction_test)\n",
    "print(\"The score is %.6f\" % RMSE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t=(1/(len(target_train)))*(np.sum(np.square(prediction_train-target_train)))\n",
    "t**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predictors_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import math\n",
    "from patsy import dmatrices\n",
    "import statsmodels.discrete.discrete_model as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sma\n",
    "from statsmodels.graphics.regressionplots import *\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = dmatrices('Class~AB\t+AF\t+AH\t+AM\t+AR\t+AX\t+AY\t+AZ\t+BC\t+BD +\tBN\t+BP\t+BQ\t+BR\t+BZ\t+CB\t+CC\t+CD +\tCF+\tCH+\tCL+\tCR+\tCS\t+CU\t+CW +\tDA\t+DE+\tDF\t+DH\t+DI\t+DL\t+DN\t+DU\t+DV\t+DY\t+EB\t+EE\t+EG\t+EH\t+EJ_B\t+EL\t+EP\t+EU\t+FC\t +FD+FE+\tFI\t+FL\t+FR\t+FS\t+GB\t+GE\t+GF\t+GH\t+GI\t+GL'\n",
    ", train, return_type = 'dataframe')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = sm.Logit(target, (predictors))\n",
    "logit.fit(method='nm').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# since we are more interested in stock marketing up, we take the second column of y as our response variable \n",
    "# we build a model to predict whether the direction will be up. \n",
    "\n",
    "# to extract the parameters directly\n",
    "logit.fit().params\n",
    "# to extract the probability of the market going up for the first 10 instances\n",
    "logit.fit().predict()[0:10] \n",
    "# in order to make a prediction as to whether the market will go up or down on a particular day, \n",
    "# we must convert these predicted probabilities into class labels, Up (1) or Down (0).\n",
    "# we will do this by threshold the probability by a predefined threshold \n",
    "threshold = 0.5 \n",
    "predict_label = pd.DataFrame(np.zeros(shape=(1250,1)), columns = ['label'])\n",
    "predict_label.iloc[logit.fit().predict()>threshold] = 1\n",
    "# we can evalue the TRAINING result by constructing a confusion matrix \n",
    "confusion_matrix(y.iloc[:,1], predict_label.iloc[:,0])\n",
    "# the diagonal elements of the confusion matrix indicate correct predictions, while the off-diagonals represent incorrect predictions. \n",
    "# in this case, logistic regression correctly predicted the movement of the market 52.2% of the time.\n",
    "print(np.mean(y.iloc[:,1] == predict_label.iloc[:,0]))\n",
    "# or use the confusion matrix to compute the accuracy \n",
    "print(confusion_matrix(y.iloc[:,1], predict_label.iloc[:,0]).diagonal().sum()* 1.0 /confusion_matrix(y.iloc[:,1], predict_label.iloc[:,0]).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.genmod.generalized_linear_model import GLM\n",
    "from statsmodels.genmod import families\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_constant = sm.add_constant(predictors_train, prepend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GLM method for logreg here so that we can retrieve the influence measures\n",
    "logit_model = GLM(target_train, X_constant, family=families.Binomial())\n",
    "logit_results = logit_model.fit()\n",
    "print(logit_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Get influence measures\n",
    "influence = logit_results.get_influence()\n",
    "\n",
    "# Obtain summary df of influence measures\n",
    "summ_df = influence.summary_frame()\n",
    "\n",
    "# Filter summary df to Cook distance\n",
    "diagnosis_df = summ_df.loc[:,['cooks_d']]\n",
    "\n",
    "# Append absolute standardized residual values\n",
    "diagnosis_df['std_resid'] = stats.zscore(logit_results.resid_pearson)\n",
    "diagnosis_df['std_resid'] = diagnosis_df.loc[:,'std_resid'].apply(lambda x: np.abs(x))\n",
    "\n",
    "# Sort by Cook's Distance\n",
    "diagnosis_df.sort_values(\"cooks_d\", ascending=False)\n",
    "diagnosis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "sfs = SequentialFeatureSelector(linear_model.LogisticRegression(multi_class='ovr',penalty='l2',solver='sag',max_iter=1000),\n",
    "                                k_features=125,\n",
    "                                forward=True,\n",
    "                                scoring='accuracy',\n",
    "                                cv=None)\n",
    "selected_features = sfs.fit(predictors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(np.array(poly.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "\n",
    "poly = PolynomialFeatures(degree=2,interaction_only=False)\n",
    "predictors_transformed= poly.fit_transform(predictors)\n",
    "\n",
    "model_log=linear_model.LogisticRegression(multi_class='ovr',penalty='l2',C=1,solver='sag',max_iter=1000)\n",
    "#Train and test sets\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors_transformed, target, test_size=0.2)\n",
    "\n",
    "model_log.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:13.751725Z",
     "iopub.status.busy": "2023-03-23T22:55:13.751035Z",
     "iopub.status.idle": "2023-03-23T22:55:13.758513Z",
     "shell.execute_reply": "2023-03-23T22:55:13.757662Z",
     "shell.execute_reply.started": "2023-03-23T22:55:13.751685Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1679006083204,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "QhpMUvKEQj4e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_log=linear_model.LogisticRegression(penalty='l2',C= 1,solver='sag',max_iter=10000)\n",
    "#model_log=linear_model.LogisticRegression(multi_class='ovr',penalty='l2',C= 1,solver='sag',max_iter=10000)\n",
    "model_log.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_train=predictors_train.copy()\n",
    "df_train['probabilities']=model_log.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',0,1)\n",
    "RMSE_train = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_test=predictors_test.copy()\n",
    "df_test['probabilities']=model_log.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',0,1)\n",
    "RMSE_test = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_log_loss(np.array(target_train),np.array(model_log.predict_proba(predictors_train)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:13.791825Z",
     "iopub.status.busy": "2023-03-23T22:55:13.791282Z",
     "iopub.status.idle": "2023-03-23T22:55:13.808836Z",
     "shell.execute_reply": "2023-03-23T22:55:13.807800Z",
     "shell.execute_reply.started": "2023-03-23T22:55:13.791791Z"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1679008802254,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "MZKsRg_gXVK7"
   },
   "outputs": [],
   "source": [
    "training=classification_report(target_train,model_log.predict(predictors_train),output_dict=True)\n",
    "testing=classification_report(target_test,model_log.predict(predictors_test),output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training results\n",
    "pd.DataFrame(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:13.825569Z",
     "iopub.status.busy": "2023-03-23T22:55:13.825264Z",
     "iopub.status.idle": "2023-03-23T22:55:13.842212Z",
     "shell.execute_reply": "2023-03-23T22:55:13.841014Z",
     "shell.execute_reply.started": "2023-03-23T22:55:13.825540Z"
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1679008809341,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "dobHNbCVjqcz",
    "outputId": "bffad4ac-07a2-4cdc-bb59-ece284e98ed7"
   },
   "outputs": [],
   "source": [
    "#test results\n",
    "pd.DataFrame(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log.predict(predictors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = log_loss(target_train, model_log.predict_proba(predictors_train))\n",
    "print(\"The score is %.6f\" % RMSE )\n",
    "RMSE = log_loss(target_test, model_log.predict_proba(predictors_test))\n",
    "print(\"The score is %.6f\" % RMSE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame()\n",
    "df1['p']=model_log.predict(predictors_train)\n",
    "df1['a']=target_train\n",
    "actual=target_train.reindex(list(range(0,489)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['p'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_train=predictors_train.copy()\n",
    "df_train['probabilities']=model_RF.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',0,1)\n",
    "RMSE = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_test=predictors_test.copy()\n",
    "df_test['probabilities']=model_RF.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',0,1)\n",
    "RMSE = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_test=train.copy()\n",
    "df_test['probabilities']=model_log.predict_proba(train)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',0,1)\n",
    "RMSE = log_loss(train1['Class'], 1-df_test['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train1['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log.predict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train=pd.DataFrame(predictors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log.predict_proba(predictors_train)[:,0]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_log.predict_proba(predictors_train)[:,7])\n",
    "#model_log.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for multiclass variable prediction alpha\n",
    "df_train=pd.DataFrame(predictors_train.copy())\n",
    "df_train['probabilities']=model_log.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE = log_loss(df_train['actual'], df_train['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for multiclass variable prediction alpha\n",
    "df_test=pd.DataFrame(predictors_test.copy())\n",
    "df_test['probabilities']=model_log.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "df_test['actual']=np.where(target_test=='A',1,0)\n",
    "RMSE = log_loss(df_test['actual'], df_test['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for multiclass variable prediction gamma\n",
    "df_train=pd.DataFrame(predictors_train.copy())\n",
    "df_train['probabilities']=model_log.predict_proba(predictors_train)[:,6]+model_log.predict_proba(predictors_train)[:,7]\n",
    "\n",
    "df_train['actual']=np.where((target_train=='M')|(target_train=='N'),1,0)\n",
    "RMSE = log_loss(df_train['actual'], df_train['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for multiclass variable prediction gamma\n",
    "df_test=pd.DataFrame(predictors_test.copy())\n",
    "df_test['probabilities']=model_log.predict_proba(predictors_test)[:,6]+model_log.predict_proba(predictors_test)[:,7]\n",
    "\n",
    "df_test['actual']=np.where((target_test=='M')|(target_test=='N'),1,0)\n",
    "RMSE = log_loss(df_test['actual'], df_test['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log.score(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_log.score(predictors_test,target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lda=LDA()\n",
    "model_lda.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training=classification_report(target_train,model_lda.predict(predictors_train),output_dict=True)\n",
    "testing=classification_report(target_test,model_lda.predict(predictors_test),output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training results\n",
    "pd.DataFrame(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame(predictors_train.copy())\n",
    "df_train['probabilities']=model_lda.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame(predictors_test.copy())\n",
    "df_test['probabilities']=model_lda.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',1,0)\n",
    "RMSE = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lda.score(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qda=QDA()\n",
    "model_qda.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame(predictors_train.copy())\n",
    "df_train['probabilities']=model_qda.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame(predictors_test.copy())\n",
    "df_test['probabilities']=model_qda.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',1,0)\n",
    "RMSE = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb=NB()\n",
    "model_nb.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.DataFrame(predictors_train.copy())\n",
    "df_train['probabilities']=model_nb.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame(predictors_test.copy())\n",
    "df_test['probabilities']=model_nb.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',1,0)\n",
    "RMSE = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model\n",
    "max_depth = 3, n_estimators = 120, random_state = 73, class_weight = 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [1,2,3,4,5,6,7,10,12,13,20,None],\n",
    "    'n_estimators': [40,60,90,105,120,135,145],\n",
    "    \"class_weight\": ['balanced']\n",
    "}\n",
    "\n",
    "\n",
    "grid_RF=GridSearchCV(model_GBC, param_grid,cv = 5)\n",
    "grid_RF.fit(predictors_train, target_train)\n",
    "grid_RF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:13.844475Z",
     "iopub.status.busy": "2023-03-23T22:55:13.844025Z",
     "iopub.status.idle": "2023-03-23T22:55:13.849964Z",
     "shell.execute_reply": "2023-03-23T22:55:13.848917Z",
     "shell.execute_reply.started": "2023-03-23T22:55:13.844432Z"
    },
    "executionInfo": {
     "elapsed": 141,
     "status": "ok",
     "timestamp": 1679009083637,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "6iII804Ag3_t"
   },
   "outputs": [],
   "source": [
    "#classifier\n",
    "model_RF=RandomForestClassifier()\n",
    "#model_RF=RandomForestClassifier(criterion=\"log_loss\",class_weight=\"balanced\")\n",
    "#model_RF=RandomForestClassifier(max_depth= None, min_samples_leaf= 1, min_samples_split= 5)\n",
    "model_RF.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:14.026774Z",
     "iopub.status.busy": "2023-03-23T22:55:14.026467Z",
     "iopub.status.idle": "2023-03-23T22:55:14.078091Z",
     "shell.execute_reply": "2023-03-23T22:55:14.077095Z",
     "shell.execute_reply.started": "2023-03-23T22:55:14.026744Z"
    }
   },
   "outputs": [],
   "source": [
    "training=classification_report(target_train,model_RF.predict(predictors_train),output_dict=True)\n",
    "testing=classification_report(target_test,model_RF.predict(predictors_test),output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:14.079570Z",
     "iopub.status.busy": "2023-03-23T22:55:14.079290Z",
     "iopub.status.idle": "2023-03-23T22:55:14.092123Z",
     "shell.execute_reply": "2023-03-23T22:55:14.090961Z",
     "shell.execute_reply.started": "2023-03-23T22:55:14.079542Z"
    }
   },
   "outputs": [],
   "source": [
    "#training results\n",
    "pd.DataFrame(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:14.094283Z",
     "iopub.status.busy": "2023-03-23T22:55:14.093693Z",
     "iopub.status.idle": "2023-03-23T22:55:14.110090Z",
     "shell.execute_reply": "2023-03-23T22:55:14.109169Z",
     "shell.execute_reply.started": "2023-03-23T22:55:14.094239Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = log_loss(target_train, model_RF.predict_proba(predictors_train))\n",
    "print(\"The score is %.6f\" % RMSE )\n",
    "RMSE = log_loss(target_test, model_RF.predict_proba(predictors_test))\n",
    "print(\"The score is %.6f\" % RMSE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_log_loss(np.array(target_train),np.array(model_RF.predict_proba(predictors_train)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=predictors_train.copy()\n",
    "df_train['probabilities']=model_RF.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE_train = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=predictors_test.copy()\n",
    "df_test['probabilities']=model_RF.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',1,0)\n",
    "RMSE_test = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.score(predictors_train,target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.score(predictors_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.predict(predictors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pppp=pd.DataFrame()\n",
    "ppp=pd.DataFrame(model_RF.predict_proba(predictors_test))[0]\n",
    "pppp['p']=ppp\n",
    "#RMSE = log_loss(target_test, ppp)\n",
    "pppp['a']=1-pppp['p']\n",
    "pppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.predict(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(target_test, model_RF.predict(predictors_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_test['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['actual_class']=np.where(df_test['actual']=='A',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=predictors_train.copy()\n",
    "df_train['predictions']=model_RF.predict(predictors_train)\n",
    "df_train['actual']=target_train\n",
    "df_test=predictors_test.copy()\n",
    "df_test['predictions']=model_RF.predict(predictors_test)\n",
    "df_test['actual']=target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['actual_class']=np.where(df_train['actual']=='A',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=predictors_train.copy()\n",
    "df_train['predictions']=model_RF.predict(np.array(predictors_train)\n",
    "df_train['actual']=target_train\n",
    "df_test=predictors_test.copy()\n",
    "df_test['predictions']=model_RF.predictnp.array((predictors_test)\n",
    "df_test['actual']=target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.predict(predictors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.predict_proba(predictors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.predict_proba(predictors_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=predictors_train.copy()\n",
    "df_train['probabilities']=model_RF.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE = log_loss(df_train['actual'], df_train['probabilities'])\n",
    "RMSE\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=pd.DataFrame(model_RF.predict_proba(np.array(predictors_train)))[:,0]\n",
    "#df_train['probabilities']=prob\n",
    "#df_train['probabilities'].info()\n",
    "np.array(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(model_RF.predict_proba(predictors_train))[0]).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(df_train['probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = log_loss(df_train['actual_class'], prob)\n",
    "RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=pd.DataFrame(model_RF.predict_proba(predictors_test))[0]\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = log_loss(df_test['actual_class'], prob)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "o=pd.DataFrame(model_RF.predict(predictors_test))\n",
    "o['predicted']=np.where(o[0]=='A',0,1)\n",
    "o.drop(0,axis=1,inplace=True)\n",
    "o2=pd.DataFrame()\n",
    "o2['actual']=target_test\n",
    "\n",
    "o2.reset_index(inplace=True)\n",
    "pd.concat([o,o2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(target_test==model_RF.predict(predictors_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp=pd.DataFrame(model_RF.predict(predictors_test),target_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame()\n",
    "#df2['p']=model_RF.predict(predictors_train)\n",
    "df2['a']=target_train\n",
    "target_train\n",
    "predictors_train\n",
    "model_RF.predict(predictors_train)\n",
    "target_train\n",
    "df2.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_RF.predict_proba(predictors_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RF.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdc=pd.read_csv('Book14.csv')\n",
    "wdc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:14.112514Z",
     "iopub.status.busy": "2023-03-23T22:55:14.111988Z",
     "iopub.status.idle": "2023-03-23T22:55:14.232152Z",
     "shell.execute_reply": "2023-03-23T22:55:14.230916Z",
     "shell.execute_reply.started": "2023-03-23T22:55:14.112470Z"
    }
   },
   "outputs": [],
   "source": [
    "#classifier\n",
    "#model_GBC= GradientBoostingClassifier()\n",
    "#model_GBC= GradientBoostingClassifier(max_depth= 2, min_samples_leaf= 2,min_samples_split= 2)\n",
    "model_GBC= XGBClassifier()\n",
    "#model_GBC= XGBClassifier(n_estimators= 10, max_depth= 3, learning_rate= 0.1, reg_alpha= 0.0, reg_lambda= 1.0)\n",
    "model_GBC.fit(predictors_train,target_train)\n",
    "#model_GBC.fit(predictors_train,target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(model_GBC.predict_proba(predictors_train)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_log_loss(np.array(target_train),np.array(model_GBC.predict_proba(predictors_train)[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.clip(np.array(model_GBC.predict_proba(predictors_train)[:,1]), 1e-15, 1 - 1e-15)\n",
    "#y_pred /= y_pred.sum(axis=1, keepdims=True)\n",
    "y_pred.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_train=predictors_train.copy()\n",
    "df_train['probabilities']=model_GBC.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',0,1)\n",
    "RMSE_train = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_test=predictors_test.copy()\n",
    "df_test['probabilities']=model_GBC.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',0,1)\n",
    "RMSE_test = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:14.233761Z",
     "iopub.status.busy": "2023-03-23T22:55:14.233348Z",
     "iopub.status.idle": "2023-03-23T22:55:14.254297Z",
     "shell.execute_reply": "2023-03-23T22:55:14.253337Z",
     "shell.execute_reply.started": "2023-03-23T22:55:14.233729Z"
    }
   },
   "outputs": [],
   "source": [
    "training=classification_report(target_train,model_GBC.predict(predictors_train),output_dict=True)\n",
    "testing=classification_report(target_test,model_GBC.predict(predictors_test),output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training results\n",
    "pd.DataFrame(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test results\n",
    "pd.DataFrame(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=predictors_train.copy()\n",
    "df_train['probabilities']=model_GBC.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE = log_loss(df_train['actual'], df_train['probabilities'])\n",
    "RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=predictors_test.copy()\n",
    "df_test['probabilities']=model_GBC.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "df_test['actual']=np.where(target_test=='A',1,0)\n",
    "RMSE = log_loss(df_test['actual'], df_test['probabilities'])\n",
    "RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred):\n",
    "    # Extracting class labels from y_true\n",
    "    y_true = y_true.astype(int)\n",
    "    \n",
    "    # Computing the number of observations for each class\n",
    "    N0 = np.sum(y_true == 0)\n",
    "    N1 = np.sum(y_true == 1)\n",
    "    \n",
    "    # Calculating the inverse prevalence weights\n",
    "    w0 = 1 / N0\n",
    "    w1 = 1 / N1\n",
    "    \n",
    "    # Rescaling the predicted probabilities\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    y_pred /= y_pred.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    # Calculating the logarithmic loss for each class\n",
    "    log_loss_0 = np.sum((1-y_true) * np.log(y_pred[:, 0])) / N0\n",
    "    log_loss_1 = np.sum(y_true * np.log(y_pred[:, 1])) / N1\n",
    "    \n",
    "    # Computing the balanced logarithmic loss\n",
    "    balanced_log_loss = (-w0 * log_loss_0 - w1 * log_loss_1)/(w0+w1)\n",
    "    \n",
    "    return balanced_log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_log_loss(target_train,(1-df_train['probabilities']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    N_0 = np.sum(1 - y_true)\n",
    "    N_1 = np.sum(y_true)\n",
    "    p_1 = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    p_0 = 1 - p_1\n",
    "    log_loss_0 = -np.sum((1 - y_true) * np.log(p_0))\n",
    "    log_loss_1 = -np.sum(y_true * np.log(p_1))\n",
    "    w_0 = 1 / N_0\n",
    "    w_1 = 1 / N_1\n",
    "    balanced_log_loss = 2*(w_0 * log_loss_0 + w_1 * log_loss_1) / (w_0 + w_1)\n",
    "    return balanced_log_loss/(N_0+N_1)\n",
    "def lgb_metric(y_true, y_pred):\n",
    "    return 'balanced_log_loss', balanced_log_loss(y_true, y_pred), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GBC = LGBMClassifier(boosting_type='goss', learning_rate=0.06733232950390658, n_estimators = 50000, \n",
    "                         early_stopping_round = 300, random_state=42,\n",
    "                        subsample=0.6970532011679706,\n",
    "                        colsample_bytree=0.6055755840633003,\n",
    "                         class_weight='balanced',\n",
    "                         metric='none', is_unbalance=True, max_depth=8)\n",
    "model_GBC.fit(predictors_train,target_train, eval_set=(predictors_test, target_test), verbose=1000,\n",
    "            eval_metric=lgb_metric)\n",
    "\n",
    "y_pred = model_GBC.predict_proba(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=pd.concat([train,train1.Alpha],axis=1)\n",
    "train2.iloc[:,63]\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = lgbm.Dataset(train2.drop(\"Alpha\",axis=1), train2.iloc[:,63],free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'GBDT',\n",
    "    'objective':\"binary\",\n",
    "    'metric':'binary_logloss',\n",
    "    'random_state': 42,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GBC = lgbm.train(params, train2, \n",
    "                      num_boost_round=500,\n",
    "                      verbose_eval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "data_dmatrix = xgb.DMatrix(data=predictors,label=target)\n",
    "from xgboost import cv\n",
    "\n",
    "\n",
    "params = {\"objective\":\"binary:logistic\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cvboosters = []\n",
    "xgb_cv = cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=90, early_stopping_rounds=10, metrics=\"auc\", as_pandas=True, seed=123 )\n",
    "\n",
    "\n",
    "xgb_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GBC= XGBClassifier( reg_lambda=2.5,scale_pos_weight = 4.71)\n",
    "#model_GBC= XGBClassifier(max_depth = 2, n_estimators = 95, random_state = 73, scale_pos_weight = 4.71)\n",
    "model_GBC.fit(predictors_train,target_train,eval_set=[(predictors_train, target_train), (predictors_test, target_test)],early_stopping_rounds=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LGBM Boost method\n",
    "model_GBC = LGBMClassifier(max_depth = 3, n_estimators = 120,random_state = 73,class_weight='balanced')\n",
    "#model_GBC = LGBMClassifier(max_depth=5,n_estimators = 200,reg_lambda=0)\n",
    "#model_GBC = LGBMClassifier(n_estimators = 121, num_leaves= 7, max_depth = 2)\n",
    "model_GBC.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#LGBM method\n",
    "model_GBC = LGBMClassifier()\n",
    "#model_GBC = LGBMClassifier(max_depth=5,n_estimators = 200,reg_lambda=0)\n",
    "#model_GBC = LGBMClassifier(n_estimators = 121, num_leaves= 7, max_depth = 2)\n",
    "model_GBC.fit(predictors_train,target_train)\n",
    "training=classification_report(target_train,model_GBC.predict(predictors_train),output_dict=True)\n",
    "testing=classification_report(target_test,model_GBC.predict(predictors_test),output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GBC.score(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GBC.score(predictors_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=predictors_test.copy()\n",
    "df['Delta_pred']=model_GBC.predict(predictors_test)\n",
    "predictors1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target1=target_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=predictors_train.copy()\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'random_seed':123,\n",
    "        'n_estimators'    :trial.suggest_int('n_estimators', 100, 300),\n",
    "        'num_leaves'      :trial.suggest_int('num_leaves', 4, 32),\n",
    "        'max_depth'       :trial.suggest_int(\"max_depth\",1,5)}\n",
    "            \n",
    "    model_GBC = lgbm.LGBMClassifier(**params)\n",
    "    model_GBC.fit(predictors_train,target_train)\n",
    "    #y_pred = model.predict(x)\n",
    "    #df_train['probabilities']=model_GBC.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "    #df_train['actual']=np.where(target_train=='A',1,0)\n",
    "    #score = log_loss(df_train['actual'], df_train['probabilities'])\n",
    "    score=model_GBC.score(predictors_test,target_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(sampler=optuna.samplers.RandomSampler(seed=123))\n",
    "study.optimize(objective, n_trials=100) \n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor\n",
    "model_svm=SVC(probability=True)\n",
    "model_svm.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regressor\n",
    "prediction_train=model_svm.predict(predictors_train)\n",
    "prediction_test=model_svm.predict(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_train=predictors_train.copy()\n",
    "df_train['probabilities']=model_svm.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',0,1)\n",
    "RMSE = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=predictors_test.copy()\n",
    "df_test['probabilities']=model_svm.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',1,0)\n",
    "RMSE = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train results\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE =  log_loss(target_train, prediction_train)\n",
    "print(\"The score is %.6f\" % RMSE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test results\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE =  log_loss(target_test, prediction_test)\n",
    "print(\"The score is %.6f\" % RMSE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:14.293748Z",
     "iopub.status.busy": "2023-03-23T22:55:14.293388Z",
     "iopub.status.idle": "2023-03-23T22:55:14.313348Z",
     "shell.execute_reply": "2023-03-23T22:55:14.312113Z",
     "shell.execute_reply.started": "2023-03-23T22:55:14.293713Z"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1679008907162,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "2oYGLfK3l6IS",
    "outputId": "2c512584-9efb-4bba-8761-6db54eb09403"
   },
   "outputs": [],
   "source": [
    "#classifier\n",
    "model_svm=SVC()\n",
    "model_svm.fit(predictors_train,target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:14.315617Z",
     "iopub.status.busy": "2023-03-23T22:55:14.314916Z",
     "iopub.status.idle": "2023-03-23T22:55:14.348483Z",
     "shell.execute_reply": "2023-03-23T22:55:14.347567Z",
     "shell.execute_reply.started": "2023-03-23T22:55:14.315570Z"
    }
   },
   "outputs": [],
   "source": [
    "training=classification_report(model_svm.predict(predictors_train),target_train,output_dict=True)\n",
    "testing=classification_report(model_svm.predict(predictors_test),target_test,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:14.350192Z",
     "iopub.status.busy": "2023-03-23T22:55:14.349873Z",
     "iopub.status.idle": "2023-03-23T22:55:14.363821Z",
     "shell.execute_reply": "2023-03-23T22:55:14.362602Z",
     "shell.execute_reply.started": "2023-03-23T22:55:14.350162Z"
    }
   },
   "outputs": [],
   "source": [
    "#training results\n",
    "pd.DataFrame(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:14.365761Z",
     "iopub.status.busy": "2023-03-23T22:55:14.365418Z",
     "iopub.status.idle": "2023-03-23T22:55:14.379667Z",
     "shell.execute_reply": "2023-03-23T22:55:14.378563Z",
     "shell.execute_reply.started": "2023-03-23T22:55:14.365718Z"
    }
   },
   "outputs": [],
   "source": [
    "#test results\n",
    "pd.DataFrame(testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model-USE SCALED FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:04:36.846828Z",
     "iopub.status.busy": "2023-06-15T07:04:36.846438Z",
     "iopub.status.idle": "2023-06-15T07:04:36.875550Z",
     "shell.execute_reply": "2023-06-15T07:04:36.874478Z",
     "shell.execute_reply.started": "2023-06-15T07:04:36.846796Z"
    }
   },
   "outputs": [],
   "source": [
    "train= pd.read_csv(\"C:/Users/rliog/Downloads/train_rev3.csv\")\n",
    "train.columns=train.columns.str.strip()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:04:41.215086Z",
     "iopub.status.busy": "2023-06-15T07:04:41.214750Z",
     "iopub.status.idle": "2023-06-15T07:04:41.222653Z",
     "shell.execute_reply": "2023-06-15T07:04:41.221580Z",
     "shell.execute_reply.started": "2023-06-15T07:04:41.215056Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop(['Gamma_pred','Delta_pred','Beta_pred'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:04:41.455111Z",
     "iopub.status.busy": "2023-06-15T07:04:41.454750Z",
     "iopub.status.idle": "2023-06-15T07:04:41.466172Z",
     "shell.execute_reply": "2023-06-15T07:04:41.465095Z",
     "shell.execute_reply.started": "2023-06-15T07:04:41.455084Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.get_dummies(train, columns=['Beta','Delta','Gamma'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:04:51.591574Z",
     "iopub.status.busy": "2023-06-15T07:04:51.591235Z",
     "iopub.status.idle": "2023-06-15T07:04:51.600008Z",
     "shell.execute_reply": "2023-06-15T07:04:51.598625Z",
     "shell.execute_reply.started": "2023-06-15T07:04:51.591550Z"
    }
   },
   "outputs": [],
   "source": [
    "#Split data into predictors and target variables\n",
    "target = train[['Beta_A',     \n",
    " 'Beta_B',      \n",
    " 'Beta_C',      \n",
    " 'Delta_A',   \n",
    " 'Delta_B',   \n",
    " 'Delta_C',   \n",
    " 'Delta_D',   \n",
    " 'Gamma_A',   \n",
    " 'Gamma_B',   \n",
    " 'Gamma_E',   \n",
    " 'Gamma_F',   \n",
    " 'Gamma_G',   \n",
    " 'Gamma_H',   \n",
    " 'Gamma_M',   \n",
    " 'Gamma_N']]\n",
    "predictors = train.drop(['Class','Alpha','Beta_A',     \n",
    " 'Beta_B',      \n",
    " 'Beta_C',      \n",
    " 'Delta_A',   \n",
    " 'Delta_B',   \n",
    " 'Delta_C',   \n",
    " 'Delta_D',   \n",
    " 'Gamma_A',   \n",
    " 'Gamma_B',   \n",
    " 'Gamma_E',   \n",
    " 'Gamma_F',   \n",
    " 'Gamma_G',   \n",
    " 'Gamma_H',   \n",
    " 'Gamma_M',   \n",
    " 'Gamma_N']\n",
    ", axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:04:54.288685Z",
     "iopub.status.busy": "2023-06-15T07:04:54.288336Z",
     "iopub.status.idle": "2023-06-15T07:04:54.296850Z",
     "shell.execute_reply": "2023-06-15T07:04:54.295458Z",
     "shell.execute_reply.started": "2023-06-15T07:04:54.288659Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train and test sets\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:35:49.575768Z",
     "iopub.status.busy": "2023-06-15T07:35:49.575281Z",
     "iopub.status.idle": "2023-06-15T07:35:49.592068Z",
     "shell.execute_reply": "2023-06-15T07:35:49.590735Z",
     "shell.execute_reply.started": "2023-06-15T07:35:49.575733Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(predictors_train)  \n",
    "predictors_scale_train = scaler.transform(predictors_train)  \n",
    "# apply same transformation to test data\n",
    "predictors_scale_test = scaler.transform(predictors_test)\n",
    "predictors_scale=scaler.transform(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(target_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a multi-label classification task\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "# define dataset\n",
    "X, y = make_multilabel_classification(n_samples=1000, n_features=10, n_classes=3, n_labels=2, random_state=1)\n",
    "# summarize dataset shape\n",
    "print(X.shape, y.shape)\n",
    "# summarize first few examples\n",
    "for i in range(10):\n",
    "\tprint(X[i], y[i])\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:05:45.698816Z",
     "iopub.status.busy": "2023-06-15T07:05:45.698428Z",
     "iopub.status.idle": "2023-06-15T07:05:55.591264Z",
     "shell.execute_reply": "2023-06-15T07:05:55.590229Z",
     "shell.execute_reply.started": "2023-06-15T07:05:45.698788Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:36:20.146158Z",
     "iopub.status.busy": "2023-06-15T07:36:20.145767Z",
     "iopub.status.idle": "2023-06-15T07:36:28.214471Z",
     "shell.execute_reply": "2023-06-15T07:36:28.213384Z",
     "shell.execute_reply.started": "2023-06-15T07:36:20.146127Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(n_inputs, n_outputs):\n",
    " model = Sequential()\n",
    " model.add(Dense(3000, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
    " #model.add(Dense(3000, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))  \n",
    " #model.add(Dense(3000, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu')) \n",
    " model.add(Dense(n_outputs, activation='sigmoid'))\n",
    " model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    " return model\n",
    "model1=get_model(56,15)\n",
    "model1.fit(predictors_scale_train, target_train, verbose=0, epochs=100)\n",
    " # make a prediction on the test set\n",
    "yhat = model1.predict(predictors_scale_test)\n",
    "yhat_train = model1.predict(predictors_scale_train)\n",
    "yhat_all=model1.predict(predictors_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array((pd.DataFrame(predictors_scale_train).describe()).loc['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:41:00.931423Z",
     "iopub.status.busy": "2023-06-15T07:41:00.931097Z",
     "iopub.status.idle": "2023-06-15T07:41:00.937624Z",
     "shell.execute_reply": "2023-06-15T07:41:00.936295Z",
     "shell.execute_reply.started": "2023-06-15T07:41:00.931400Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat = yhat.round()\n",
    "yhat=pd.DataFrame(yhat)\n",
    "#predictors_scale=pd.DataFrame(predictors_scale)\n",
    "yhat_train = yhat_train.round()\n",
    "yhat_train=pd.DataFrame(yhat_train)\n",
    "yhat_all = yhat_all.round()\n",
    "yhat_all=pd.DataFrame(yhat_all)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:42:25.731805Z",
     "iopub.status.busy": "2023-06-15T07:42:25.731353Z",
     "iopub.status.idle": "2023-06-15T07:42:25.764521Z",
     "shell.execute_reply": "2023-06-15T07:42:25.762858Z",
     "shell.execute_reply.started": "2023-06-15T07:42:25.731766Z"
    }
   },
   "outputs": [],
   "source": [
    "yhat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([pd.DataFrame(predictors_scale), pd.DataFrame(yhat_all)], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('train_rev3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat.to_csv('yhat_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test.to_csv('target_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=0\n",
    "for i in target.columns:\n",
    "    predictors_scale[i]=yhat[m]\n",
    "    m=m+1\n",
    "predictors_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:13:17.347283Z",
     "iopub.status.busy": "2023-06-15T07:13:17.346778Z",
     "iopub.status.idle": "2023-06-15T07:13:17.363641Z",
     "shell.execute_reply": "2023-06-15T07:13:17.362769Z",
     "shell.execute_reply.started": "2023-06-15T07:13:17.347244Z"
    }
   },
   "outputs": [],
   "source": [
    "#train accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(target_train, yhat_train)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T07:13:18.132071Z",
     "iopub.status.busy": "2023-06-15T07:13:18.131505Z",
     "iopub.status.idle": "2023-06-15T07:13:18.145030Z",
     "shell.execute_reply": "2023-06-15T07:13:18.143621Z",
     "shell.execute_reply.started": "2023-06-15T07:13:18.132044Z"
    }
   },
   "outputs": [],
   "source": [
    "#test accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(target_test, yhat)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = tf.convert_to_tensor(predictors_scale_train)\n",
    "tensor1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network using tensorflow library\n",
    "\n",
    "model = Sequential([\n",
    "tf.keras.Input(shape=(56,489)),\n",
    "Dense(units=1000, activation='relu'),\n",
    "Dense(units=1000, activation='relu'),\n",
    "Dense(units=1000, activation='relu'),\n",
    "Dense(units=15, activation='softmax')])\n",
    "\n",
    "model.compile(loss='binary_crossentropy')\n",
    "model.fit(predictors_scale_train,np.array(target_train),epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(target_test)==(np.array(r).reshape(1,123))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(r).reshape(1,123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(predictors_scale_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=np.where(model.predict(predictors_scale_test)>0.5,1,0)\n",
    "#(r==np.array(target_test))\n",
    "pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model.predict(predictors_scale_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(predictors_train)  \n",
    "predictors_scale_train = scaler.transform(predictors_train)  \n",
    "# apply same transformation to test data\n",
    "predictors_scale_test = scaler.transform(predictors_test)  \n",
    "target_train=np.array(target_train)\n",
    "target_test=np.array(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(predictors_train)  \n",
    "predictors_scale_train = pd.DataFrame(scaler.transform(predictors_train))\n",
    "# apply same transformation to test data\n",
    "predictors_scale_test = pd.DataFrame(scaler.transform(predictors_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network using tensorflow library\n",
    "tf.keras.regularizers.L2(100)\n",
    "model = Sequential([\n",
    "Dense(units=1000, activation='relu',kernel_regularizer='l2'),\n",
    "Dense(units=1000, activation='relu',kernel_regularizer='l2'),\n",
    "Dense(units=1000, activation='relu',kernel_regularizer='l2'),\n",
    "Dense(units=1, activation='sigmoid',kernel_regularizer='l2') \n",
    "])\n",
    "\n",
    "model.compile(loss=BinaryCrossentropy() )\n",
    "#model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(0.001),)\n",
    "model.fit(predictors_scale_train,target_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(predictors_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(\n",
    "    predictors_scale_train, target_train, target_test, sample_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_train=pd.DataFrame(predictors_scale_train.copy())\n",
    "\n",
    "df_train['probabilities']=model.predict(predictors_scale_train)\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',0,1)\n",
    "RMSE_train = log_loss(target_train, df_train['probabilities'])\n",
    "RMSE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_test=pd.DataFrame(predictors_scale_test.copy())\n",
    "\n",
    "df_test['probabilities']=model.predict(predictors_scale_test)\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',0,1)\n",
    "RMSE_test = log_loss(target_test, df_test['probabilities'])\n",
    "RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T06:33:28.599890Z",
     "iopub.status.busy": "2023-06-15T06:33:28.599465Z",
     "iopub.status.idle": "2023-06-15T06:33:53.289757Z",
     "shell.execute_reply": "2023-06-15T06:33:53.288985Z",
     "shell.execute_reply.started": "2023-06-15T06:33:28.599862Z"
    },
    "executionInfo": {
     "elapsed": 1027,
     "status": "ok",
     "timestamp": 1679014148112,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "dqfF8sO9-f8e",
    "outputId": "60e5811b-7e33-4aa0-fac6-a071cbf06f1e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#classifier\n",
    "#model_nn=MLPClassifier(hidden_layer_sizes=(1000,1000), activation='relu',random_state=1,max_iter=1000)\n",
    "model_nn=MLPClassifier(hidden_layer_sizes=(500,500), activation='relu',random_state=10,alpha=3,max_iter=5000,learning_rate='adaptive',learning_rate_init=0.0001)\n",
    "#model_nn=MLPClassifier(hidden_layer_sizes=(500,500), activation='relu', *, solver='adam', alpha=0.0001, \n",
    "                                      #batch_size='auto', learning_rate='constant', learning_rate_init=0.001, \n",
    "                                      #power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, \n",
    "                                      #verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                                      #early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, \n",
    "                                      #epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
    "#model_nn.fit(predictors_scale_train,target_train)\n",
    "model_nn.fit(predictors_scale_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_log_loss(np.array(target_train),np.array(model_nn.predict_proba(predictors_scale_train)[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_train=pd.DataFrame(predictors_scale_train.copy())\n",
    "\n",
    "df_train['probabilities']=model_nn.predict_proba(predictors_scale_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',0,1)\n",
    "RMSE_train = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_test=pd.DataFrame(predictors_scale_test.copy())\n",
    "\n",
    "df_test['probabilities']=model_nn.predict_proba(predictors_scale_test)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',0,1)\n",
    "RMSE_test = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.score(predictors_scale_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.score(predictors_scale_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform oversampling to address class imbalance\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "predictors_train_resampled, target_train_resampled = oversampler.fit_resample(predictors_scale_train, target_train)\n",
    "\n",
    "# Perform undersampling to further balance the class distribution\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "predictors_train_resampled, target_train_resampled = undersampler.fit_resample(predictors_train_resampled, target_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:15.745587Z",
     "iopub.status.busy": "2023-03-23T22:55:15.744858Z",
     "iopub.status.idle": "2023-03-23T22:55:15.782329Z",
     "shell.execute_reply": "2023-03-23T22:55:15.780702Z",
     "shell.execute_reply.started": "2023-03-23T22:55:15.745542Z"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1679014150459,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "YS21jrP-l-i3"
   },
   "outputs": [],
   "source": [
    "training=classification_report(target_train,model_nn.predict(predictors_train),output_dict=True)\n",
    "testing=classification_report(target_test,model_nn.predict(predictors_test),output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:15.784897Z",
     "iopub.status.busy": "2023-03-23T22:55:15.784200Z",
     "iopub.status.idle": "2023-03-23T22:55:15.805171Z",
     "shell.execute_reply": "2023-03-23T22:55:15.803960Z",
     "shell.execute_reply.started": "2023-03-23T22:55:15.784852Z"
    }
   },
   "outputs": [],
   "source": [
    "#training results\n",
    "pd.DataFrame(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:15.807722Z",
     "iopub.status.busy": "2023-03-23T22:55:15.806985Z",
     "iopub.status.idle": "2023-03-23T22:55:15.830165Z",
     "shell.execute_reply": "2023-03-23T22:55:15.828961Z",
     "shell.execute_reply.started": "2023-03-23T22:55:15.807664Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-15T06:40:29.059744Z",
     "iopub.status.busy": "2023-06-15T06:40:29.059324Z",
     "iopub.status.idle": "2023-06-15T06:40:29.091156Z",
     "shell.execute_reply": "2023-06-15T06:40:29.090436Z",
     "shell.execute_reply.started": "2023-06-15T06:40:29.059711Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(model_nn.predict(predictors_scale_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "\n",
    "df['pred']=model_nn.predict(predictors_test)\n",
    "df['actual']=target_test\n",
    "df\n",
    "model_nn.predict(predictors_train)\n",
    "#(target_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_scale_train=pd.DataFrame(predictors_scale_train)\n",
    "df_train=predictors_scale_train.copy()\n",
    "\n",
    "df_train['probabilities']=model_nn.predict_proba(predictors_scale_train)[:,0]\n",
    "\n",
    "df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE = log_loss(df_train['actual'], df_train['probabilities'])\n",
    "RMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_scale_test=pd.DataFrame(predictors_scale_test)\n",
    "df_test=predictors_scale_test.copy()\n",
    "\n",
    "df_test['probabilities']=model_nn.predict_proba(predictors_scale_test)[:,0]\n",
    "df_test['actual']=np.where(target_test=='A',1,0)\n",
    "RMSE = log_loss(df_test['actual'], df_test['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV model-GBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:15.832718Z",
     "iopub.status.busy": "2023-03-23T22:55:15.832012Z",
     "iopub.status.idle": "2023-03-23T22:55:36.463093Z",
     "shell.execute_reply": "2023-03-23T22:55:36.461614Z",
     "shell.execute_reply.started": "2023-03-23T22:55:15.832671Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [3,5,10,15,20,None],\n",
    "    \"min_samples_split\": [2,5,7,10],\n",
    "    \"min_samples_leaf\": [1,2,5]\n",
    "}\n",
    "\n",
    "\n",
    "grid_cv = GridSearchCV(model_RF, param_grid, n_jobs=-1, cv=3).fit(predictors_train, target_train)\n",
    "\n",
    "print(\"Param for GS\", grid_cv.best_params_)\n",
    "print(\"CV score for GS\", grid_cv.best_score_)\n",
    "#print(\"Train AUC ROC Score for GS: \", roc_auc_score(target_train, grid_cv.predict(predictors_train)))\n",
    "#print(\"Test AUC ROC Score for GS: \", roc_auc_score(target_test, grid_cv.predict(predictors_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV model-Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(120)],\n",
    "    \"random_state\": [1],\n",
    "    \"alpha\": [3,9,16,21,29,35],\n",
    "    \"max_iter\": [1000,1500,2000]\n",
    "}\n",
    "\n",
    "\n",
    "grid_cv = GridSearchCV(model_nn, param_grid, n_jobs=-1, cv=3).fit(predictors1_train, target_train)\n",
    "\n",
    "print(\"Param for GS\", grid_cv.best_params_)\n",
    "print(\"CV score for GS\", grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:36.465928Z",
     "iopub.status.busy": "2023-03-23T22:55:36.465036Z",
     "iopub.status.idle": "2023-03-23T22:55:36.488572Z",
     "shell.execute_reply": "2023-03-23T22:55:36.487536Z",
     "shell.execute_reply.started": "2023-03-23T22:55:36.465879Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "training=classification_report(grid_cv.predict(predictors_train),target_train,output_dict=True)\n",
    "testing=classification_report(grid_cv.predict(predictors_test),target_test,output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:36.490387Z",
     "iopub.status.busy": "2023-03-23T22:55:36.490035Z",
     "iopub.status.idle": "2023-03-23T22:55:36.504896Z",
     "shell.execute_reply": "2023-03-23T22:55:36.503815Z",
     "shell.execute_reply.started": "2023-03-23T22:55:36.490352Z"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1679014151779,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "0ejEFcuSmPyX",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "625a22cd-88ee-4a38-e9e0-d945d817fec8"
   },
   "outputs": [],
   "source": [
    "\n",
    "#training results\n",
    "pd.DataFrame(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:36.506846Z",
     "iopub.status.busy": "2023-03-23T22:55:36.506246Z",
     "iopub.status.idle": "2023-03-23T22:55:36.519286Z",
     "shell.execute_reply": "2023-03-23T22:55:36.518338Z",
     "shell.execute_reply.started": "2023-03-23T22:55:36.506813Z"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1679014153667,
     "user": {
      "displayName": "Y L",
      "userId": "10906315492438391707"
     },
     "user_tz": 420
    },
    "id": "XuuO0nl7mpaQ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "09929d18-8ead-49ee-f43f-597849e6b75d"
   },
   "outputs": [],
   "source": [
    "#test results\n",
    "pd.DataFrame(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:36.521234Z",
     "iopub.status.busy": "2023-03-23T22:55:36.520643Z",
     "iopub.status.idle": "2023-03-23T22:55:36.534698Z",
     "shell.execute_reply": "2023-03-23T22:55:36.533468Z",
     "shell.execute_reply.started": "2023-03-23T22:55:36.521199Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5),scoring='metric'):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    #train_scores_mean = RMSE_train\n",
    "    #train_scores_std = np.std(train_scores, axis=1)\n",
    "    #test_scores_mean = RMSE_test\n",
    "    #test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:36.536714Z",
     "iopub.status.busy": "2023-03-23T22:55:36.536265Z",
     "iopub.status.idle": "2023-03-23T22:55:40.445827Z",
     "shell.execute_reply": "2023-03-23T22:55:40.444650Z",
     "shell.execute_reply.started": "2023-03-23T22:55:36.536668Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "title = \"Learning Curves (Logistic Regression)\"\n",
    "cv = 4\n",
    "plot_learning_curve(model_nn, title, \n",
    "                    predictors_scale_train,target_train, ylim=(0.65, 1.20), cv=cv, n_jobs=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": predictors,\n",
    "    \"y\": target,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 4,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "for ax_idx, estimator in enumerate([model_nn]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variance Inflation Factor\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors11=predictors[['Delta_pred_B','Delta_pred_C','Delta_pred_D','Gamma_pred_B','Gamma_pred_E','Gamma_pred_F','Gamma_pred_G',\t'Gamma_pred_H',\t'Gamma_pred_M',\t'Gamma_pred_N']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictorsB=train\n",
    "predictorsB=predictorsB.iloc[:,1:56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = predictorsB.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(predictorsB.values, i)\n",
    "                          for i in range(len(predictorsB.columns))]\n",
    "  \n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "vif_data[vif_data['VIF']>10]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictors1.to_csv('train6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p=predictors.iloc[:,0:3] + predictors.iloc[:,8:13]\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=pd.DataFrame()\n",
    "i['Residuals']=est2.resid\n",
    "i['variable']=predictors.iloc[:,2]\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est2.resid\n",
    "predictors[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(17,20):\n",
    "    X=predictors.drop(predictors.columns[i],axis=1)\n",
    "    y=target\n",
    "    X2 = sm.add_constant(X)\n",
    "    est = sm.OLS(y, X2)\n",
    "    est2 = est.fit()\n",
    "    print('--------------------------',predictors.columns[i],'-----------------------------')\n",
    "    #plt.scatter(predictors.iloc[:,i],est2.resid)\n",
    "    #plt.show()\n",
    "    df=pd.DataFrame()\n",
    "    df['Residuals']=est2.resid\n",
    "    df['variable']=predictors.iloc[:,i]\n",
    "    #x=df['Residuals']\n",
    "    #y=df['variable']\n",
    "    fig = px.scatter(df,df['variable'],df['Residuals'],  trendline=\"ols\")\n",
    "    fig.show()\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(train.columns):\n",
    "    sns.factorplot(i,'Class',data=train)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sm.OLS('YearRemodAdd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "target = train3updated['YearRemodAdd']\n",
    "predictors = train3updated.drop(['YearRemodAdd'], axis=1)\n",
    "\n",
    "for i in range(100):\n",
    "    sample=random.sample(features,3)\n",
    "    X = predictors.loc[:,sample]\n",
    "    y = target\n",
    "    X2 = sm.add_constant(X)\n",
    "    est = sm.OLS(y, X2)\n",
    "    est2 = est.fit()\n",
    "    print('XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX')\n",
    "    print('For first',i, 'features')\n",
    "    print(est2.summary())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(predictors.columns.drop(['YearRemodAdd','other_exterior2nd']))\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frame = pd.DataFrame()\n",
    "Frame['number_of_features']=[]\n",
    "Frame['features_in _model']=[]\n",
    "Frame['R_squared']=[]\n",
    "for j in range(41):\n",
    "    for i in range(200):\n",
    "        sample=random.sample(features,j)\n",
    "        X = predictors.loc[:,sample]\n",
    "        y = predictors['YearRemodAdd']\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        Frame.loc[len(Frame.index)]=[j,str(sample),est2.rsquared]\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frame = pd.DataFrame()\n",
    "Frame['number_of_features']=[]\n",
    "Frame['features_in _model']=[]\n",
    "Frame['R_squared']=[]\n",
    "for j in range(42):\n",
    "    for i in range(400):\n",
    "        sample=random.sample(features,j)\n",
    "        X = predictors.loc[:,sample]\n",
    "        y = predictors['YearRemodAdd']\n",
    "        X2 = sm.add_constant(X)\n",
    "        est = sm.OLS(y, X2)\n",
    "        est2 = est.fit()\n",
    "        Frame.loc[len(Frame.index)]=[j,str(sample),est2.rsquared]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group=Frame.groupby('number_of_features')\n",
    "group.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group=Frame.groupby('number_of_features')\n",
    "group.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train3updated[['other_exterior2nd','YearRemodAdd']].corr()\n",
    "model2=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group=Frame.groupby('number_of_features')\n",
    "#group=Frame.groupby(['number_of_features','features_in_model'])\n",
    "pd.DataFrame(group.max()).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Frame.to_csv('Frame.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['EJ','GL']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['DV','CL']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train.corr()<-0.9).iloc[:,20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "corrmat = train.corr()\n",
    "f, ax = plt.subplots(figsize=(15, 15))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saleprice correlation matrix\n",
    "k = 10 #number of variables for heatmap\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(train3updated[cols].values.T)\n",
    "sns.set(font_scale=0.65)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 1}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(model_RF.predict_proba(test)).iloc[:,1:2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T22:55:40.447427Z",
     "iopub.status.busy": "2023-03-23T22:55:40.447031Z",
     "iopub.status.idle": "2023-03-23T22:55:40.462376Z",
     "shell.execute_reply": "2023-03-23T22:55:40.461253Z",
     "shell.execute_reply.started": "2023-03-23T22:55:40.447382Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"Id\": test['Id'],\n",
    "        \"class_0\": 1-np.array(pd.DataFrame(model_RF.predict_proba(test)).iloc[:,1:2][1])\n",
    "        \"class_1\": np.array(pd.DataFrame(model_RF.predict_proba(test)).iloc[:,1:2][1])\n",
    "    })\n",
    "\n",
    "submission.to_csv('submission_XGB2--1312223411.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predictors1=predictors[['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF']]\n",
    "predictors2=predictors[['2ndFlrSF','OpenPorchSF','EnclosedPorch','ScreenPorch']]\n",
    "predictors3=predictors[['TotalBsmtFin','TotalSF','TotalBath','TotalPorch','BuildToRemod']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = predictors.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(predictors.values, i)\n",
    "                          for i in range(len(predictors.columns))]\n",
    "  \n",
    "vif_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_data['VIF'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "variance_inflation_factor(predictors.values, 5)\n",
    "predictors_incl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = predictors.columns\n",
    "\n",
    "for j in range(48):\n",
    "    for i in range(2,49):\n",
    "        predictors_incl=pd.DataFrame(np.concatenate([predictors.iloc[:,j:j+1], predictors.iloc[:,0:i],predictors.iloc[:,i+1:]], axis=1))\n",
    "        vif=variance_inflation_factor(predictors_incl.values, j)\n",
    "        print('VIF',i-1,vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#pd.concat([predictors.iloc[:,0:3], predictors.iloc[:,1:4]], axis=0,join=\"inner\")\n",
    "#predictors.iloc[:,0:13]\n",
    "df3 = predictors.iloc[:,0:3].append(predictors.iloc[:,1:4],ignore_index=False)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = predictors.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(predictors.values, i)\n",
    "                          for i in range(len(predictors.columns))]\n",
    "  \n",
    "vif_data['VIF'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# VIF dataframe\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = train3.columns\n",
    "  \n",
    "# calculating VIF for each feature\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(train3.values, i)\n",
    "                          for i in range(len(train3.columns))]\n",
    "  \n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "vif_data[vif_data['VIF']>40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df=predictors.corr()\n",
    "criteria1=df.iloc[0:48,0:48]>0.7\n",
    "criteria2=df.iloc[0:48,0:48]<1\n",
    "dff=df[criteria1 & criteria2]\n",
    "dff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train3updated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train3updated.iloc[:,0:50].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "predictors_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "list(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"x\": [5, 2], \"y\": [4, 7], \"z\": [9, 3]})\n",
    "df2 = pd.DataFrame({\"a\": [1, 3], \"b\": [1, 9], \"c\": [29, 30]})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df3 = df1.append(df2,ignore_index=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Select features\n",
    "features =train3.columns[40:50]\n",
    "\n",
    "for feature in features:\n",
    "    # Create figure \n",
    "    fig = px.scatter(train3, feature, 'YearRemodAdd', \n",
    "                     trendline=\"ols\", trendline_scope=\"overall\", trendline_color_override=\"red\",\n",
    "                     template = 'simple_white',\n",
    "                     color_discrete_sequence = ['#1192AA'])\n",
    "    \n",
    "    # Set Title and x/y axis labels\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Value\",\n",
    "        yaxis_title=\"Frequency\",\n",
    "        showlegend = False,\n",
    "        font = dict(\n",
    "                size = 14\n",
    "                ),    \n",
    "        title={\n",
    "            'text': feature,\n",
    "            'y':0.95,\n",
    "            'x':0.5\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    # Display\n",
    "    fig.show() # for Kaggle version\n",
    "    #fig.show(\"png\") # for GitHub version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train error\n",
    "dftrain=predictors_train.copy()\n",
    "dftrain['pred']=list(pd.DataFrame(model_RF.predict_proba(predictors_train)).iloc[:,1:2][1])\n",
    "dftrain['actual']=target_train\n",
    "log_loss(dftrain['actual'],dftrain['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test error\n",
    "dftest=predictors_test.copy()\n",
    "dftest['pred']=list(pd.DataFrame(model_RF.predict_proba(predictors_test)).iloc[:,1:2][1])\n",
    "dftest['actual']=target_test\n",
    "log_loss(dftest['actual'],dftest['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['pred']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=train[['Beta','Delta']]\n",
    "predictors=pd.get_dummies(predictors,columns=['Beta','Delta'], drop_first=False)\n",
    "target=train['Alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train.to_csv('hkiuh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test sets\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(predictors, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(predictors_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(predictors_test,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(clf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting classifier\n",
    "model_vote=VotingClassifier(voting='soft',estimators=[('log',model_log),('lda',model_lda),('rf',model_RF),('gbc',model_GBC),('nn',model_nn)])\n",
    "model_vote.fit(predictors_scale_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_scale_train=pd.DataFrame(predictors_scale_train)\n",
    "df_train=predictors_scale_train.copy()\n",
    "df_train['probabilities']=model_vote.predict_proba(predictors_scale_train)[:,0]\n",
    "\n",
    "df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE_train = log_loss(df_train['actual'], df_train['probabilities'])\n",
    "RMSE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_scale_test=pd.DataFrame(predictors_scale_test)\n",
    "df_test=predictors_scale_test.copy()\n",
    "df_test['probabilities']=model_vote.predict_proba(predictors_scale_test)[:,0]\n",
    "\n",
    "df_test['actual']=np.where(target_test=='A',1,0)\n",
    "RMSE_test = log_loss(df_test['actual'], df_test['probabilities'])\n",
    "RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LGBMClassifier(nun_leaves=10,max_depth = 3, n_estimators = 120, random_state = 73, class_weight = 'balanced')\n",
    "clf2.fit(predictors_train,target_train)\n",
    "#predictions2 = pd.DataFrame(clf2.predict_proba(target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=predictors_train.copy()\n",
    "df_train['probabilities']=clf2.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE_train = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=predictors_test.copy()\n",
    "df_test['probabilities']=clf2.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',1,0)\n",
    "RMSE_test = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "predictors=train.drop('Class',axis=1)\n",
    "target=train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.EJ = train.EJ.replace({'A':0,'B':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors=train.drop(['Class','Alpha','Beta','Delta','Gamma'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = lgbm.LGBMClassifier(max_depth = 3, n_estimators = 120, random_state = 73, class_weight = 'balanced')\n",
    "clf2.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LGBM method\n",
    "model_GBC = LGBMClassifier(scale_pos_weight=509/108)\n",
    "#model_GBC = LGBMClassifier(max_depth=5,n_estimators = 200,reg_lambda=0)\n",
    "#model_GBC = LGBMClassifier(n_estimators = 121, num_leaves= 7, max_depth = 2)\n",
    "model_GBC.fit(predictors_train,target_train)\n",
    "training=classification_report(target_train,model_GBC.predict(predictors_train),output_dict=True)\n",
    "testing=classification_report(target_test,model_GBC.predict(predictors_test),output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train, predictors_test,target_train,target_test=train_test_split(predictors,target,test_size=0.2,random_state=15534453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GBC= XGBClassifier(max_depth = 2, n_estimators = 95, random_state = 73, scale_pos_weight = 4.71,reg_lambda=1)\n",
    "model_GBC.fit(predictors_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=predictors_train.copy()\n",
    "df_train['probabilities']=model_GBC.predict_proba(predictors_train)[:,0]\n",
    "\n",
    "#df_train['actual']=np.where(target_train=='A',1,0)\n",
    "RMSE_train = log_loss(target_train, 1-df_train['probabilities'])\n",
    "RMSE_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class variable prediction\n",
    "df_test=predictors_test.copy()\n",
    "df_test['probabilities']=model_GBC.predict_proba(predictors_test)[:,0]\n",
    "\n",
    "#df_test['actual']=np.where(target_test=='A',0,1)\n",
    "RMSE = log_loss(target_test, 1-df_test['probabilities'])\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
